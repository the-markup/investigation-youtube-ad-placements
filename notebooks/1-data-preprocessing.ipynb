{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "This notebook parses and processes the API responses from the \"PlacementSuggestionService\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from terms import policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "data_in = '../data/input/placements_api/'\n",
    "fn_hate_info = '../data/input/hate_terms_additional_info.csv'\n",
    "\n",
    "# outputs\n",
    "data_dir = '../data/output/placements_api_keyword_status/'\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "fn_hate = os.path.join(data_dir, \"hate.csv\")\n",
    "fn_social_justice = os.path.join(data_dir, \"social_justice.csv\")\n",
    "fn_policy = os.path.join(data_dir, \"policy.csv\")\n",
    "fn_basewords = os.path.join(data_dir, \"basewords.csv\")\n",
    "fn_adhoc = os.path.join(data_dir, \"adhoc.csv\")\n",
    "\n",
    "data_dir_2 = '../data/output/placements_api_suggestions/'\n",
    "os.makedirs(data_dir_2, exist_ok=True)\n",
    "\n",
    "fn_social_justice_videos = os.path.join(data_dir_2, 'videos_for_social_justice_terms.csv')\n",
    "fn_hate_videos = os.path.join(data_dir_2, 'videos_for_social_justice_terms.csv')\n",
    "fn_social_justice_channels = os.path.join(data_dir_2, 'channels_for_social_justice_terms.csv')\n",
    "fn_hate_channels = os.path.join(data_dir_2, 'channels_for_hate_terms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "838"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob(data_in + '*/*.json')\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the API responses\n",
    "Here we iterate through each of the raw json responses, and structure them in a human-readible way.\n",
    "\n",
    "Refer to `../data/reference/placements_api_example_responses/full.json` for an example what this looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 838/838 [00:00<00:00, 9314.77it/s]\n"
     ]
    }
   ],
   "source": [
    "errors = {}\n",
    "dataset = []\n",
    "for fn in tqdm(files):\n",
    "    record = {\n",
    "        'fn' : fn,\n",
    "        'search_term' : fn.replace(data_in, '').split('/')[-1] \\\n",
    "                          .replace('+', ' ').replace('.json', '')\n",
    "    }\n",
    "    data = json.load(open(fn))\n",
    "    \n",
    "    if data == dict():\n",
    "        record['is_blocked'] = True\n",
    "        dataset.append(record)\n",
    "        continue\n",
    "    else:\n",
    "        record['is_blocked'] = False\n",
    "    try:\n",
    "        youtube_channels_ = data.get('4')\n",
    "        if youtube_channels_:\n",
    "            youtube_channels_number = youtube_channels_['2']\n",
    "            youtube_channels = youtube_channels_.get('1', [])\n",
    "\n",
    "            # multi\n",
    "            channel_meta = []\n",
    "            for youtube_channel in youtube_channels:\n",
    "                youtube_channel_meta_ = youtube_channel['8']\n",
    "\n",
    "                row = dict(\n",
    "                    youtube_channel_id = youtube_channel['7']['1']['1'],\n",
    "                    youtube_channel_name = youtube_channel['7']['2'],\n",
    "                    youtube_channel_subs = youtube_channel_meta_.get('2'),\n",
    "                    youtube_channel_videos = youtube_channel_meta_['1'],\n",
    "                    youtube_channel_thumbnail = youtube_channel_meta_['3']\n",
    "                )\n",
    "                channel_meta.append(row)\n",
    "\n",
    "            record['n_youtube_channels'] = youtube_channels_number\n",
    "            record['youtube_channels'] = channel_meta\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        # 1\n",
    "        websites = data.get('1')\n",
    "        if websites:    \n",
    "            number_websites = websites['2']\n",
    "            website_list = websites.get('1', [])\n",
    "\n",
    "            # mutlti\n",
    "            website_meta = []\n",
    "            for website_dict in website_list:\n",
    "                row = dict(\n",
    "                    domain = website_dict['1'],\n",
    "                    impressions_per_week = website_dict['4']\n",
    "                )\n",
    "                website_meta.append(row)\n",
    "            record['n_websites'] = number_websites\n",
    "            record['website'] = website_meta\n",
    "    except:pass\n",
    "    try:\n",
    "\n",
    "        # 2\n",
    "        apps = data.get('2')\n",
    "        if apps:\n",
    "            number_of_apps = apps['2']\n",
    "            apps_list = apps.get('1', [])\n",
    "\n",
    "            # multi\n",
    "            apps_meta = []\n",
    "            for app in apps_list:\n",
    "                row = dict(\n",
    "                    app_name = app['2'],\n",
    "                    add_creator = app['4'],\n",
    "                    app_thumbnail = app['5'],\n",
    "                    app_id = app['6']['1'],\n",
    "                    add_category = app['6']['2']    \n",
    "                )\n",
    "                apps_meta.append(row)\n",
    "\n",
    "            record['n_apps'] = number_of_apps\n",
    "            record['apps'] = apps_meta\n",
    "    except:pass\n",
    "    try:\n",
    "\n",
    "        # 5\n",
    "        youtube = data.get('5')\n",
    "        if youtube:\n",
    "            youtube_number_videos = youtube['2']\n",
    "            youtube_videos = youtube.get('1', [])\n",
    "\n",
    "            #multi\n",
    "            youtube_video_meta = []\n",
    "            for youtube_video in youtube_videos:\n",
    "                row = dict(\n",
    "                    youtube_video_id = youtube_video['1'],\n",
    "                    youtube_video_title = youtube_video['2'],\n",
    "                    youtube_video_views = youtube_video['3'],\n",
    "                    youtube_video_channel = youtube_video['4']    \n",
    "                )\n",
    "\n",
    "                youtube_video_meta.append(row)\n",
    "            record['n_youtube_videos'] = youtube_number_videos\n",
    "            record['youtube_videos'] = youtube_video_meta\n",
    "    except:pass\n",
    "    dataset.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['n_youtube_channels', 'n_youtube_videos']:\n",
    "    df[col] = df[col].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We deciphered four kinds of API responses (`full`, `blocked`, `partially blocked` and `empty`). We provided examples for each kind of response in `../data/reference/placements_api_response_examples`. Please read the methodology for more detail about each kind of response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_status(row):\n",
    "    \"\"\"\n",
    "    Determines the status of suggested placements for a given keyword's response.\n",
    "    \"\"\"\n",
    "    if row['is_blocked'] == True:\n",
    "        return 'Blocked'\n",
    "    elif row['n_youtube_channels'] == 0 and row['n_youtube_videos'] == 0:\n",
    "        return 'Empty'\n",
    "    elif row['n_youtube_videos'] == 1:\n",
    "        return 'Partial Block'\n",
    "    else:\n",
    "        return 'Full'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['status'] = df.apply(determine_status, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocked = df[df.fn.str.contains('/blocked/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(blocked[['search_term', \"is_blocked\", 'status', 'n_youtube_videos', 'n_youtube_channels']], \n",
    "              on=['search_term'], how='left', \n",
    "              suffixes=('', '_no_spaces'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['n_youtube_channels', \n",
    "                   'is_blocked_no_spaces',\n",
    "                   'search_term'], \n",
    "               ascending=False, \n",
    "               inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hate = df[df.fn.str.contains('/hate/')]\n",
    "social_justice = df[df.fn.str.contains('/social_justice/')]\n",
    "policy = df[df.fn.str.contains('/policy/')]\n",
    "word = df[df.fn.str.contains('/blocked_basewords/')]\n",
    "adhoc = df[(df.fn.str.contains('adhoc/'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87, 62, 150)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hate), len(social_justice), len(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the terms and responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_cols = [\n",
    "    'search_term', \n",
    "    'status',\n",
    "    'status_no_spaces',\n",
    "    'n_youtube_videos',\n",
    "    'n_youtube_channels',\n",
    "    'n_youtube_videos_no_spaces',\n",
    "    'n_youtube_channels_no_spaces',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add links for additional info on each hate term.\n",
    "hate = hate.merge(pd.read_csv(fn_hate_info), on='search_term')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hate[display_cols + ['additional_info_link']].to_csv(fn_hate, index=False)\n",
    "social_justice[display_cols].to_csv(fn_social_justice, index=False)\n",
    "policy[display_cols].to_csv(fn_policy, index=False)\n",
    "word[display_cols].to_csv(fn_basewords, index=False)\n",
    "adhoc[display_cols].to_csv(fn_adhoc, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we write everything to an excel notebook...\n",
    "writer = pd.ExcelWriter('../data/reference/what_is_blocked.xlsx')\n",
    "hate[display_cols + ['additional_info_link']].to_excel(writer, 'hate', index=False)\n",
    "social_justice[display_cols].to_excel(writer, 'social_justice', index=False)\n",
    "policy[display_cols].to_excel(writer, 'policy', index=False)\n",
    "adhoc[display_cols].to_excel(writer, 'adhoc', index=False)\n",
    "word[display_cols].to_excel(writer, 'basewords', index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What YouTube channels and videos are suggested?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_channels = []\n",
    "youtube_videos = []\n",
    "websites = []\n",
    "for results in [_ for _ in dataset if _['fn'] in df['fn'].tolist()]:\n",
    "    is_banned = 'blocked/' in results['fn']\n",
    "    _row = {\n",
    "        'search_term' : results['search_term'],   \n",
    "        'is_banned' : is_banned\n",
    "    }\n",
    "    \n",
    "    if results.get('youtube_channels'):\n",
    "        for channel_meta in results.get('youtube_channels'):\n",
    "            row = _row.copy()\n",
    "            row = {\n",
    "                **_row, **channel_meta\n",
    "            }\n",
    "            row['channel_url'] = ('youtube.com/channel/'\n",
    "                                 f'{channel_meta[\"youtube_channel_id\"]}')\n",
    "            youtube_channels.append(row)\n",
    "    else:\n",
    "        youtube_channels.append(_row)\n",
    "            \n",
    "    if results.get('youtube_videos'):\n",
    "        for video_meta in results.get('youtube_videos'):\n",
    "            row = _row.copy()\n",
    "            row = {\n",
    "                **_row, **video_meta\n",
    "            } \n",
    "            row['video_url']= ('youtube.com/watch/?v='\n",
    "                            f'{video_meta[\"youtube_video_id\"]}')\n",
    "            youtube_videos.append(row)\n",
    "    else:\n",
    "        youtube_videos.append(_row)\n",
    "            \n",
    "    if results.get('website'):\n",
    "        for web_meta in results.get('website'):\n",
    "            row = _row.copy()\n",
    "            row = {\n",
    "                **_row, **web_meta\n",
    "            }\n",
    "            websites.append(row)\n",
    "    else:\n",
    "        websites.append(_row)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_channel = pd.DataFrame(youtube_channels)\n",
    "df_vids = pd.DataFrame(youtube_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vids = df_vids[~df_vids.youtube_video_id.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1385"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_vids[df_vids.search_term.isin(hate.search_term)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vids[\"video_id\"] = df_vids[~df_vids.video_url.isnull()].apply(\n",
    "    lambda x: x['video_url'].split('?v=')[-1] if x['video_url'] else None, axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1314"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vids[df_vids.search_term.isin(hate.search_term)].youtube_video_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vids[df_vids.search_term.isin(hate.search_term)].to_csv(\n",
    "    fn_hate_videos, index=False\n",
    ")\n",
    "df_vids[df_vids.search_term.isin(social_justice.search_term)].to_csv(\n",
    "    fn_social_justice_videos, index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_channel[df_channel.search_term.isin(hate.search_term)].to_csv(\n",
    "    fn_hate_channels, index=False\n",
    ")\n",
    "df_channel[df_channel.search_term.isin(social_justice.search_term)].to_csv(\n",
    "    fn_social_justice_videos, index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
