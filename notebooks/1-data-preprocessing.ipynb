{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "This notebook parses and processes the API responses from the \"PlacementSuggestionService\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "data_in = '../data/input/placements_api/'\n",
    "fn_hate_info = '../data/input/hate_terms_additional_info.csv'\n",
    "\n",
    "# outputs\n",
    "data_dir = '../data/output/placements_api_keyword_status/'\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "fn_hate = os.path.join(data_dir, \"hate.csv\")\n",
    "fn_social_justice = os.path.join(data_dir, \"social_justice.csv\")\n",
    "fn_policy = os.path.join(data_dir, \"policy.csv\")\n",
    "fn_basewords = os.path.join(data_dir, \"basewords.csv\")\n",
    "fn_adhoc = os.path.join(data_dir, \"adhoc.csv\")\n",
    "\n",
    "data_dir_2 = '../data/output/placements_api_suggestions/'\n",
    "os.makedirs(data_dir_2, exist_ok=True)\n",
    "fn_social_justice_videos = os.path.join(data_dir_2, 'videos_for_social_justice_terms.csv')\n",
    "fn_hate_videos = os.path.join(data_dir_2, 'videos_for_hate_terms.csv')\n",
    "fn_social_justice_channels = os.path.join(data_dir_2, 'channels_for_social_justice_terms.csv')\n",
    "fn_hate_channels = os.path.join(data_dir_2, 'channels_for_hate_terms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "802"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob(data_in + '*/*.json')\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the API responses\n",
    "Refer to `../data/reference/placements_api_example_responses/full.json` for an example what a typical API response looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 802/802 [00:00<00:00, 14556.31it/s]\n"
     ]
    }
   ],
   "source": [
    "errors = {}\n",
    "dataset = []\n",
    "for fn in tqdm(files):\n",
    "    record = {\n",
    "        'fn' : fn,\n",
    "        'search_term' : fn.replace(data_in, '').split('/')[-1].replace('+', ' ').replace('.json', '')\n",
    "    }\n",
    "    data = json.load(open(fn))\n",
    "    if data == dict():\n",
    "        record['is_blocked'] = True\n",
    "        dataset.append(record)\n",
    "        continue\n",
    "    else:\n",
    "        record['is_blocked'] = False\n",
    "    try:\n",
    "        # 4 - YouTube channel suggestions\n",
    "        youtube_channels_ = data.get('4')\n",
    "        if youtube_channels_:\n",
    "            youtube_channels_number = youtube_channels_['2']\n",
    "            youtube_channels = youtube_channels_.get('1', [])\n",
    "\n",
    "            channel_meta = []\n",
    "            for youtube_channel in youtube_channels:\n",
    "                youtube_channel_meta_ = youtube_channel['8']\n",
    "\n",
    "                row = dict(\n",
    "                    youtube_channel_id = youtube_channel['7']['1']['1'],\n",
    "                    youtube_channel_name = youtube_channel['7']['2'],\n",
    "                    youtube_channel_subs = youtube_channel_meta_.get('2'),\n",
    "                    youtube_channel_videos = youtube_channel_meta_['1'],\n",
    "                    youtube_channel_thumbnail = youtube_channel_meta_['3']\n",
    "                )\n",
    "                channel_meta.append(row)\n",
    "            record['n_youtube_channels'] = youtube_channels_number\n",
    "            record['youtube_channels'] = channel_meta\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        # 5 - YouTube video suggestions\n",
    "        youtube = data.get('5')\n",
    "        if youtube:\n",
    "            youtube_number_videos = youtube['2']\n",
    "            youtube_videos = youtube.get('1', [])\n",
    "            \n",
    "            youtube_video_meta = []\n",
    "            for youtube_video in youtube_videos:\n",
    "                row = dict(\n",
    "                    youtube_video_id = youtube_video['1'],\n",
    "                    youtube_video_title = youtube_video['2'],\n",
    "                    youtube_video_views = youtube_video['3'],\n",
    "                    youtube_video_channel = youtube_video['4']    \n",
    "                )\n",
    "                youtube_video_meta.append(row)\n",
    "            record['n_youtube_videos'] = youtube_number_videos\n",
    "            record['youtube_videos'] = youtube_video_meta\n",
    "    except:pass\n",
    "    dataset.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['n_youtube_channels', 'n_youtube_videos']:\n",
    "    df[col] = df[col].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_status(row: dict) -> str:\n",
    "    \"\"\"\n",
    "    Determines the status (`full`, `blocked`, `partially blocked` or `empty`) \n",
    "    of or a given keyword's response.\n",
    "    \n",
    "    Examples for each kind of response in \n",
    "    `../data/reference/placements_api_response_examples`. \n",
    "    \n",
    "    Please read the methodology for more detail.\n",
    "    \"\"\"\n",
    "    if row['is_blocked'] == True:\n",
    "        return 'Blocked'\n",
    "    elif row['n_youtube_channels'] == 0 and row['n_youtube_videos'] == 0:\n",
    "        return 'Empty'\n",
    "    elif row['n_youtube_videos'] == 1:\n",
    "        return 'Partial Block'\n",
    "    return 'Full'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['status'] = df.apply(determine_status, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocked = df[df.fn.str.contains('/blocked/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_cols = [\n",
    "    'search_term', \n",
    "    'is_blocked', \n",
    "    'status', \n",
    "    'n_youtube_videos', \n",
    "    'n_youtube_channels'\n",
    "]\n",
    "\n",
    "df = df.merge(blocked[merge_cols], \n",
    "              on=['search_term'], how='left', \n",
    "              suffixes=('', '_no_spaces'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create order of statuses for sorting\n",
    "status_order = [\"Full\", \"Empty\", \"Partial Block\", \"Blocked\"]\n",
    "for col in ['status', 'status_no_spaces']:\n",
    "    df[col] = pd.Categorical(df[col], status_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['status',\n",
    "                   'search_term',\n",
    "                   'status_no_spaces'], \n",
    "               ascending=True, \n",
    "               inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hate = df[df.fn.str.contains('/hate/')]\n",
    "social_justice = df[df.fn.str.contains('/social_justice/')]\n",
    "policy = df[df.fn.str.contains('/policy/')]\n",
    "word = df[df.fn.str.contains('/blocked_basewords/')]\n",
    "adhoc = df[(df.fn.str.contains('adhoc/'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87, 62, 150)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hate), len(social_justice), len(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the terms and responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_cols = [\n",
    "    'search_term', \n",
    "    'status',\n",
    "    'status_no_spaces',\n",
    "    'n_youtube_videos',\n",
    "    'n_youtube_channels',\n",
    "    'n_youtube_videos_no_spaces',\n",
    "    'n_youtube_channels_no_spaces',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add links for additional info on each hate term.\n",
    "hate = hate.merge(pd.read_csv(fn_hate_info), on='search_term')\n",
    "\n",
    "# save the status of terms from each keyword list\n",
    "hate[display_cols + ['additional_info_link']].to_csv(fn_hate, index=False)\n",
    "social_justice[display_cols].to_csv(fn_social_justice, index=False)\n",
    "policy[display_cols].to_csv(fn_policy, index=False)\n",
    "word[display_cols].to_csv(fn_basewords, index=False)\n",
    "adhoc[display_cols].to_csv(fn_adhoc, index=False)\n",
    "\n",
    "\n",
    "# Here we write everything to a spreadsheet...\n",
    "writer = pd.ExcelWriter('../data/reference/what_is_blocked.xlsx')\n",
    "hate[display_cols + ['additional_info_link']].to_excel(writer, 'hate', index=False)\n",
    "social_justice[display_cols].to_excel(writer, 'social_justice', index=False)\n",
    "policy[display_cols].to_excel(writer, 'policy', index=False)\n",
    "adhoc[display_cols].to_excel(writer, 'adhoc', index=False)\n",
    "word[display_cols].to_excel(writer, 'basewords', index=False)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fn</th>\n",
       "      <th>search_term</th>\n",
       "      <th>is_blocked</th>\n",
       "      <th>n_youtube_channels</th>\n",
       "      <th>youtube_channels</th>\n",
       "      <th>n_youtube_videos</th>\n",
       "      <th>youtube_videos</th>\n",
       "      <th>status</th>\n",
       "      <th>is_blocked_no_spaces</th>\n",
       "      <th>status_no_spaces</th>\n",
       "      <th>n_youtube_videos_no_spaces</th>\n",
       "      <th>n_youtube_channels_no_spaces</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>../data/input/placements_api/blocked/black liv...</td>\n",
       "      <td>black lives matter</td>\n",
       "      <td>False</td>\n",
       "      <td>96118.0</td>\n",
       "      <td>[{'youtube_channel_id': 'UCIveFvW-ARp_B_Rckhwe...</td>\n",
       "      <td>2029797.0</td>\n",
       "      <td>[{'youtube_video_id': 'A2o15RCtSS0', 'youtube_...</td>\n",
       "      <td>Full</td>\n",
       "      <td>False</td>\n",
       "      <td>Full</td>\n",
       "      <td>2029797.0</td>\n",
       "      <td>96118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>../data/input/placements_api/social_justice/bl...</td>\n",
       "      <td>black lives matter</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Blocked</td>\n",
       "      <td>False</td>\n",
       "      <td>Full</td>\n",
       "      <td>2029797.0</td>\n",
       "      <td>96118.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    fn         search_term  \\\n",
       "760  ../data/input/placements_api/blocked/black liv...  black lives matter   \n",
       "302  ../data/input/placements_api/social_justice/bl...  black lives matter   \n",
       "\n",
       "     is_blocked  n_youtube_channels  \\\n",
       "760       False             96118.0   \n",
       "302        True                 NaN   \n",
       "\n",
       "                                      youtube_channels  n_youtube_videos  \\\n",
       "760  [{'youtube_channel_id': 'UCIveFvW-ARp_B_Rckhwe...         2029797.0   \n",
       "302                                                NaN               NaN   \n",
       "\n",
       "                                        youtube_videos   status  \\\n",
       "760  [{'youtube_video_id': 'A2o15RCtSS0', 'youtube_...     Full   \n",
       "302                                                NaN  Blocked   \n",
       "\n",
       "    is_blocked_no_spaces status_no_spaces  n_youtube_videos_no_spaces  \\\n",
       "760                False             Full                   2029797.0   \n",
       "302                False             Full                   2029797.0   \n",
       "\n",
       "     n_youtube_channels_no_spaces  \n",
       "760                       96118.0  \n",
       "302                       96118.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['search_term'] == 'black lives matter']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What YouTube channels and videos are suggested?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_channels = []\n",
    "youtube_videos = []\n",
    "websites = []\n",
    "for results in [_ for _ in dataset if _['fn'] in df['fn'].tolist()]:\n",
    "    _row = {'search_term' : results['search_term']}\n",
    "    \n",
    "    if results.get('youtube_channels'):\n",
    "        for channel_meta in results.get('youtube_channels'):\n",
    "            row = _row.copy()\n",
    "            row = {**_row, **channel_meta}\n",
    "            row['channel_url'] = ('youtube.com/channel/'\n",
    "                                 f'{channel_meta[\"youtube_channel_id\"]}')\n",
    "            youtube_channels.append(row)\n",
    "    else:\n",
    "        youtube_channels.append(_row)\n",
    "            \n",
    "    if results.get('youtube_videos'):\n",
    "        for video_meta in results.get('youtube_videos'):\n",
    "            row = _row.copy()\n",
    "            row = {**_row, **video_meta} \n",
    "            row['video_url']= ('youtube.com/watch/?v='\n",
    "                            f'{video_meta[\"youtube_video_id\"]}')\n",
    "            youtube_videos.append(row)\n",
    "    else:\n",
    "        youtube_videos.append(_row)\n",
    "            \n",
    "    if results.get('website'):\n",
    "        for web_meta in results.get('website'):\n",
    "            row = _row.copy()\n",
    "            row = {**_row, **web_meta}\n",
    "            websites.append(row)\n",
    "    else:\n",
    "        websites.append(_row)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_channel = pd.DataFrame(youtube_channels)\n",
    "df_vids = pd.DataFrame(youtube_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1385"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vids = df_vids[~df_vids.youtube_video_id.isnull()]\n",
    "len(df_vids[df_vids.search_term.isin(hate.search_term)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get video id\n",
    "df_vids[\"video_id\"] = df_vids[~df_vids.video_url.isnull()].apply(\n",
    "    lambda x: x['video_url'].split('?v=')[-1] if x['video_url'] else None, \n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bandaid_search_term(search_term):\n",
    "    \"\"\"Make clear if the search_term was a space-removal term\"\"\"\n",
    "    if search_term in df[~df.status_no_spaces.isnull()].search_term.tolist():\n",
    "        return search_term.replace(' ', '')\n",
    "    return search_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vids.loc[:, \"search_term\"] = df_vids.search_term.apply(get_bandaid_search_term)\n",
    "df_channel.loc[:, \"search_term\"] = df_channel.search_term.apply(get_bandaid_search_term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1140"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many unique videos were suggested from the hate terms?\n",
    "df_vids[df_vids.search_term.isin(hate.search_term)].youtube_video_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the parsed suggested videos\n",
    "df_vids[df_vids.search_term.isin(hate.search_term)].to_csv(\n",
    "    fn_hate_videos, index=False\n",
    ")\n",
    "df_vids[df_vids.search_term.isin(social_justice.search_term)].to_csv(\n",
    "    fn_social_justice_videos, index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the parsed suggested channels\n",
    "df_channel[df_channel.search_term.isin(hate.search_term)].to_csv(\n",
    "    fn_hate_channels, index=False\n",
    ")\n",
    "df_channel[df_channel.search_term.isin(social_justice.search_term)].to_csv(\n",
    "    fn_social_justice_channels, index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
